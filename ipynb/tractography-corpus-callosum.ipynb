{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity Matrices, ROI Intersections and Density Maps\n",
    "\n",
    "This example is meant to be an introduction to some of the streamline tools\n",
    "available in dipy. Some of the functions covered in this example are\n",
    "``target``, ``connectivity_matrix`` and ``density_map``. ``target`` allows one\n",
    "to filter streamlines that either pass through or do not pass through some\n",
    "region of the brain, ``connectivity_matrix`` groups and counts streamlines\n",
    "based on where in the brain they begin and end, and finally, density map counts\n",
    "the number of streamlines that pass though every voxel of some image.\n",
    "\n",
    "To get started we'll need to have a set of streamlines to work with. We'll use\n",
    "EuDX along with the CsaOdfModel to make some streamlines. Let's import the\n",
    "modules and download the data we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again, please first remove the folder /Users/arokem/.dipy/stanford_hardi \n",
      "All files already in /Users/arokem/.dipy/stanford_hardi.\n",
      "All files already in /Users/arokem/.dipy/stanford_hardi.\n",
      "All files already in /Users/arokem/.dipy/stanford_hardi.\n"
     ]
    }
   ],
   "source": [
    "from dipy.tracking.eudx import EuDX\n",
    "from dipy.reconst import peaks, shm\n",
    "from dipy.tracking import utils\n",
    "\n",
    "from dipy.data import read_stanford_labels, fetch_stanford_t1, read_stanford_t1\n",
    "\n",
    "hardi_img, gtab, labels_img = read_stanford_labels()\n",
    "data = hardi_img.get_data()\n",
    "labels = labels_img.get_data()\n",
    "\n",
    "fetch_stanford_t1()\n",
    "t1 = read_stanford_t1()\n",
    "t1_data = t1.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've loaded an image called ``labels_img`` which is a map of tissue types such\n",
    "that every integer value in the array ``labels`` represents an anatomical\n",
    "structure or tissue type [#]_. For this example, the image was created so that\n",
    "white matter voxels have values of either 1 or 2. We'll use\n",
    "``peaks_from_model`` to apply the ``CsaOdfModel`` to each white matter voxel\n",
    "and estimate fiber orientations which we can use for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "white_matter = (labels == 1) | (labels == 2)\n",
    "csamodel = shm.CsaOdfModel(gtab, 6)\n",
    "csapeaks = peaks.peaks_from_model(model=csamodel,\n",
    "                                  data=data,\n",
    "                                  sphere=peaks.default_sphere,\n",
    "                                  relative_peak_threshold=.8,\n",
    "                                  min_separation_angle=45,\n",
    "                                  mask=white_matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use EuDX to track all of the white matter. To keep things reasonably\n",
    "fast we use ``density=2`` which will result in 8 seeds per voxel. We'll set\n",
    "``a_low`` (the parameter which determines the threshold of FA/QA under which\n",
    "tracking stops) to be very low because we've already applied a white matter\n",
    "mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seeds = utils.seeds_from_mask(white_matter, density=2)\n",
    "streamline_generator = EuDX(csapeaks.peak_values, csapeaks.peak_indices,\n",
    "                            odf_vertices=peaks.default_sphere.vertices,\n",
    "                            a_low=.05, step_sz=.5, seeds=seeds)\n",
    "affine = streamline_generator.affine\n",
    "streamlines = list(streamline_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first of the tracking utilities we'll cover here is ``target``. This\n",
    "function takes a set of streamlines and a region of interest (ROI) and returns\n",
    "only those streamlines that pass though the ROI. The ROI should be an array\n",
    "such that the voxels that belong to the ROI are ``True`` and all other voxels\n",
    "are ``False`` (this type of binary array is sometimes called a mask). This\n",
    "function can also exclude all the streamlines that pass though an ROI by\n",
    "setting the ``include`` flag to ``False``. In this example we'll target the\n",
    "streamlines of the corpus callosum. Our ``labels`` array has a sagittal slice\n",
    "of the corpus callosum identified by the label value 2. We'll create an ROI\n",
    "mask from that label and create two sets of streamlines, those that intersect\n",
    "with the ROI and those that don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc_slice = labels == 2\n",
    "cc_streamlines = utils.target(streamlines, cc_slice, affine=affine)\n",
    "cc_streamlines = list(cc_streamlines)\n",
    "\n",
    "other_streamlines = utils.target(streamlines, cc_slice, affine=affine,\n",
    "                                 include=False)\n",
    "other_streamlines = list(other_streamlines)\n",
    "assert len(other_streamlines) + len(cc_streamlines) == len(streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use some of dipy's visualization tools to display the ROI we targeted\n",
    "above and all the streamlines that pass though that ROI. The ROI is the yellow\n",
    "region near the center of the axial image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Position (0.00,0.00,1.00)\n",
      "Camera Focal Point (0.00,0.00,0.00)\n",
      "Camera View Up (0.00,1.00,0.00)\n",
      "-------------------------------------\n",
      "Camera New Position (-1.00,0.00,0.00)\n",
      "Camera New Focal Point (0.00,0.00,0.00)\n",
      "Camera New View Up (0.00,0.00,1.00)\n"
     ]
    }
   ],
   "source": [
    "from dipy.viz import fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "\n",
    "# Make display objects\n",
    "color = line_colors(cc_streamlines)\n",
    "cc_streamlines_actor = fvtk.line(cc_streamlines, line_colors(cc_streamlines))\n",
    "#cc_ROI_actor = fvtk.contour(cc_slice, levels=[1], colors=[(1., 1., 0.)],\n",
    "#                            opacities=[1.])\n",
    "\n",
    "vol_actor = fvtk.slicer(t1_data, voxsz=(1.0, 1.0, 1.0), plane_i=[40],\n",
    "                        plane_j=None, plane_k=None, outline=False)\n",
    "\n",
    "# Add display objects to canvas\n",
    "r = fvtk.ren()\n",
    "r.SetBackground(1, 1, 1)\n",
    "fvtk.add(r, vol_actor)\n",
    "\n",
    "#fvtk.record(r, n_frames=1, out_path='axial_slice.png',\n",
    "#            size=(800, 800))\n",
    "\n",
    "fvtk.add(r, cc_streamlines_actor)\n",
    "#fvtk.add(r, cc_ROI_actor)\n",
    "\n",
    "\n",
    "# Save figures\n",
    "#fvtk.record(r, n_frames=10, out_path='./corpuscallosum_axial/fig',\n",
    "#            size=(800, 800))\n",
    "fvtk.camera(r, [-1, 0, 0], [0, 0, 0], viewup=[0, 0, 1])\n",
    "fvtk.record(r, n_frames=360, out_path='./corpuscallosum_sagittal/fig', az_ang=1,\n",
    "            size=(800, 800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've set ``return_mapping`` and ``mapping_as_streamlines`` to ``True`` so that\n",
    "``connectivity_matrix`` returns all the streamlines in ``cc_streamlines``\n",
    "grouped by their endpoint.\n",
    "\n",
    "Because we're typically only interested in connections between gray matter\n",
    "regions, and because the label 0 represents background and the labels 1 and 2\n",
    "represent white matter, we discard the first three rows and columns of the\n",
    "connectivity matrix.\n",
    "\n",
    "We can now display this matrix using matplotlib, we display it using a log\n",
    "scale to make small values in the matrix easier to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./corpuscallosum-sagittal-movie.mp4\n",
      "[MoviePy] Writing video ./corpuscallosum-sagittal-movie.mp4\n",
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./corpuscallosum-sagittal-movie.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "imseq = mp.ImageSequenceClip('./corpuscallosum_sagittal/', fps=18)\n",
    "imseq.write_videofile('./corpuscallosum-sagittal-movie.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M, grouping = utils.connectivity_matrix(cc_streamlines, labels, affine=affine,\n",
    "                                        return_mapping=True,\n",
    "                                        mapping_as_streamlines=True)\n",
    "M[:3, :] = 0\n",
    "M[:, :3] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example track there are more streamlines connecting regions 11 and\n",
    "54 than any other pair of regions. These labels represent the left and right\n",
    "superior frontal gyrus respectively. These two regions are large, close\n",
    "together, have lots of corpus callosum fibers and are easy to track so this\n",
    "result should not be a surprise to anyone.\n",
    "\n",
    "However, the interpretation of streamline counts can be tricky. The\n",
    "relationship between the underlying biology and the streamline counts will\n",
    "depend on several factors, including how the tracking was done, and the correct\n",
    "way to interpret these kinds of connectivity matrices is still an open question\n",
    "in the diffusion imaging literature.\n",
    "\n",
    "The next function we'll demonstrate is ``density_map``. This function allows\n",
    "one to represent the spatial distribution of a track by counting the density of\n",
    "streamlines in each voxel. For example, let's take the track connecting the\n",
    "left and right superior frontal gyrus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_superiorfrontal_track = grouping[11, 54]\n",
    "shape = labels.shape\n",
    "dm = utils.density_map(lr_superiorfrontal_track, shape, affine=affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this density map and the streamlines so that they can be\n",
    "visualized together. In order to save the streamlines in a \".trk\" file we'll\n",
    "need to move them to \"trackvis space\", or the representation of streamlines\n",
    "specified by the trackvis Track File format.\n",
    "\n",
    "To do that, we will use tools available in [nibabel](http://nipy.org/nibabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Save density map\n",
    "dm_img = nib.Nifti1Image(dm.astype(\"int16\"), hardi_img.get_affine())\n",
    "dm_img.to_filename(\"lr-superiorfrontal-dm.nii.gz\")\n",
    "\n",
    "# Make a trackvis header so we can save streamlines\n",
    "voxel_size = labels_img.get_header().get_zooms()\n",
    "trackvis_header = nib.trackvis.empty_header()\n",
    "trackvis_header['voxel_size'] = voxel_size\n",
    "trackvis_header['dim'] = shape\n",
    "trackvis_header['voxel_order'] = \"RAS\"\n",
    "\n",
    "# Move streamlines to \"trackvis space\"\n",
    "trackvis_point_space = utils.affine_for_trackvis(voxel_size)\n",
    "lr_sf_trk = utils.move_streamlines(lr_superiorfrontal_track,\n",
    "                                   trackvis_point_space, input_space=affine)\n",
    "lr_sf_trk = list(lr_sf_trk)\n",
    "\n",
    "# Save streamlines\n",
    "for_save = [(sl, None, None) for sl in lr_sf_trk]\n",
    "nib.trackvis.write(\"lr-superiorfrontal.trk\", for_save, trackvis_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
